---
author: "Kim, Geunho"
date: 2019-07-29
draft: false
title: "Hadoop DataNode"
---


## Architecture 
하둡 클러스터에서 DataNode는 파일 블록이 저장되는 노드이다. 십 수대의 서버에서 수백, 수천대의 서버에 DataNode가 기동되어 네트워크 상에서 거대한 파일 시스템의 블록 구조를 가지게 된다. 일반적인 파일 시스템의 블록 구조가 네트워크를 통해 확장, 추상화 되었다. 

일반적인 파일 시스템의 기본 블록 크기가 4KB 정도 인것에 비해(1), DataNode에 저장되는 블록의 크기는 64MB~128MB의 크기를 가진다. HDFS가 저장하고 처리하고자 하는 파일 하나의 크기가 작게는 수 백 메가바이트에서 크게는 테라, 페타 바이트 수준이기 때문이다.(2) 

HDFS의 NameNode가 여러가지 보조 장치를 통해 파일 시스템의 네임스페이스와 메타 데이터를 유실하지 않도록 발전한것 처럼, DataNode도 이러한 분산 환경에서 파일 블록이 언제든 유실되거나 접근할 수 없는 상황을 가정하고 설계되었는데, 분산된 노드에 파일 블록의 복제본을 두는 방식이다. HDFS에서는 기본적으로 세 개의 파일 블록 복제본을 서로 다른 DataNode에서 보관하도록 처리한다. 하나의 DataNode 데이터가 모두 유실되더라도 다른 DataNode에 저장된 복제본 블록에 접근해서 온전한 파일을 읽을 수 있다. 

클라이언트는 HDFS의 파일을 읽거나 쓸때, NameNode로 부터 파일 블록들의 위치를 응답받은 다음, 그 정보를 가지고 DataNode로 직접 읽거나 쓰기 요청을 한다. 


(1) 파일 시스템의 종류와 설정에 따라 다르다. 디스크의 크기가 훨씬 작았던 과거에는 512B 정도로 작았다.  
(2) 그렇기 때문에 작은 크기로 나뉘어진 여러 개의 파일을 처리하는 용도로는 부적합하다. 